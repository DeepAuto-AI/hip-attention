{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "ensemble_model_setting = \"random_pruning\"\n",
    "ensemble_method = \"final_attn\"\n",
    "ensemble_method_final = \"all_agree\"\n",
    "ensemble_model_n = 5\n",
    "ensemble_per_attn_iter_n = 5\n",
    "\n",
    "layer_id\n",
    "ensemble_per_layer_n\n",
    "\n",
    "\n",
    "for i in [0, 5, 20, 30, 40]:\n",
    "    ensemble_particular_layer = i\n",
    "\n",
    "###\n",
    "default_path = f'./cache/ensemble/llama13b_32k/models/default/l_{layer_id}_{sampling_method}.pth'\n",
    "path = f'./cache/ensemble/llama13b_32k/models/{ensemble_model_setting}_{ensemble_method}_{ensemble_method_final}/l_{layer_id}_m_{ensemble_model_n}_{i}_pl_{ensemble_per_layer_n}_pat{ensemble_per_attn_iter_n}_ln{ensemble_particular_layer}.pth'\n",
    "###\n",
    "\n",
    "state = torch.load(path, map_location='cpu')\n",
    "\n",
    "model_indices = state['indices']\n",
    "ks = state['ks']\n",
    "q_timber = state['q_timber']\n",
    "k = state['k']\n",
    "v = state['v']\n",
    "mask_k = state['mask_k']\n",
    "block_size_q = state['block_size_q']\n",
    "block_size_k = state['block_size_k']\n",
    "ensemble = state['ensemble'],\n",
    "ensemble_model_setting = state['ensemble_model_setting' ]\n",
    "ensemble_method = state['ensemble_method'],\n",
    "ensemble_method_final = state['ensemble_method_final']\n",
    "ensemble_per_layer_n = state['ensemble_per_layer_n']\n",
    "ensemble_per_attn_iter_n = state['ensemble_per_attn_iter_n']\n",
    "ensemble_model_n = state['ensemble_model_n']\n",
    "ensemble_particular_layer = state['ensemble_particular_layer']\n",
    "layer_id = state['layer_id']\n",
    "model_id = state['model_id']"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
